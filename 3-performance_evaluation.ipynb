{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import itertools\n",
    "import matplotlib\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 10 # 全体のフォントサイズが変更されます。\n",
    "plt.rcParams['figure.figsize'] = (3.5, 3.5) \n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_path = '/Prove/Yoshihisa/HEIF_ghost/PKL/pkl_single/'\n",
    "double_path = '/Prove/Yoshihisa/HEIF_ghost/PKL/pkl_second/'\n",
    "\n",
    "num_files_to_extract = 1500\n",
    "file_extension = \".pkl\"\n",
    "\n",
    "files_single = [file for file in os.listdir(single_path) if file.endswith(file_extension)]\n",
    "files_double = [file for file in os.listdir(double_path) if file.endswith(file_extension)]\n",
    "\n",
    "# ランダムにファイルを抽出\n",
    "random_files_single = random.sample(files_single, num_files_to_extract)\n",
    "random_files_double = random.sample(files_double, num_files_to_extract)\n",
    "\n",
    "files_double = random.sample(files_double, 8550)\n",
    "\n",
    "list_single = [os.path.join(single_path, filename) for filename in random_files_single]\n",
    "list_double = [os.path.join(double_path, filename) for filename in random_files_double]\n",
    "files_double = [os.path.join(double_path, filename) for filename in files_double]\n",
    "\n",
    "\n",
    "combined_list = list_single + list_double\n",
    "\n",
    "print(\"Length of the combined list:\", len(combined_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d755d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_finalQP(filename):\n",
    "    match = re.search(r'2ndQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_1stQP(filename):\n",
    "    match = re.search(r'1stQP(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def is_double_compressed(mean_difference, final_QP, threshold):\n",
    "    energy_clamp = torch.clamp(mean_difference, min=0.0)\n",
    "    energy = torch.sum(torch.square(energy_clamp))\n",
    "    # energy = torch.sum(torch.square(mean_difference))\n",
    "    mean_difference_right_clamp = torch.clamp(mean_difference[final_QP+1:52], min=0.0)\n",
    "    right_energy = torch.sum(torch.square(mean_difference_right_clamp))\n",
    "    # right_energy = torch.sum(torch.square(energy))\n",
    "    \n",
    "    # エネルギー比を計算して閾値と比較\n",
    "    if energy <= 0:\n",
    "        return -1\n",
    "    \n",
    "    else:\n",
    "        if (right_energy / energy) > threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False  \n",
    "        \n",
    "def get_possible_1stQP(mean_difference, final_QP):\n",
    "    mean_difference_right = torch.clamp(mean_difference[final_QP+1:52], min=0)\n",
    "    mean_difference_right_square = torch.square(mean_difference_right)\n",
    "    right_energy = torch.sum(mean_difference_right_square)\n",
    "    normalized = mean_difference_right_square / right_energy\n",
    "    \n",
    "    #peaksは与えられたすべての条件を満たすインデックスを返す\n",
    "    peaks, _ = find_peaks(normalized.cpu().numpy(), height=0.01)\n",
    "    peaks_values = normalized[peaks]\n",
    "\n",
    "    peaks_ratio = peaks_values / peaks_values.sum()\n",
    "    peaks += (final_QP+1)\n",
    "    # print(peaks_ratio, peaks)\n",
    "\n",
    "    if len(peaks_ratio) > 0:\n",
    "        QP = peaks[np.argmax(peaks_ratio)]\n",
    "    else:\n",
    "        QP = None\n",
    "\n",
    "    return QP, peaks, peaks_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "ground_truth_labels = []\n",
    "\n",
    "random.shuffle(combined_list)\n",
    "for filename in combined_list:\n",
    "    loaded_data = np.load(filename, allow_pickle=True)\n",
    "    ghost_results, ghost_results_shifted = loaded_data\n",
    "    data = [shifted - original for original, shifted in zip(ghost_results, ghost_results_shifted)]    \n",
    "    data_tensor = torch.tensor(data)\n",
    "\n",
    "    final_QP = extract_finalQP(filename)\n",
    "    \n",
    "    is_double = is_double_compressed(data_tensor, final_QP, 0.6)\n",
    "\n",
    "    results.append((filename, is_double))\n",
    "        \n",
    "    if \"2ndQP\" in filename:\n",
    "        ground_truth_labels.append(1)\n",
    "    else:\n",
    "        ground_truth_labels.append(0)\n",
    "        \n",
    "# Classification report            \n",
    "predicted_labels = [int(is_double) for _, is_double in results]\n",
    "\n",
    "ground_truth_labels = [label for label in ground_truth_labels]\n",
    "# print((predicted_labels, ground_truth_labels))\n",
    "\n",
    "accuracy = sum(1 for true_label, pred_label in zip(ground_truth_labels, predicted_labels) if true_label == pred_label) / len(ground_truth_labels)\n",
    "report = classification_report(ground_truth_labels, predicted_labels, labels=[0,1], target_names=['Single Compressed', 'Double Compressed'], zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45864a8c-83e5-4c78-8979-a0098b93dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "\n",
    "# データをシャッフル\n",
    "random.shuffle(combined_list)\n",
    "\n",
    "# 各スレッショルドで計算したFPRとTPRを保持するリストを作成\n",
    "fpr_values = []\n",
    "tpr_values = []\n",
    "\n",
    "# 各スレッショルドでループ\n",
    "for threshold in thresholds:\n",
    "    results = []\n",
    "    ground_truth_labels = []\n",
    "\n",
    "    # 各ファイルに対してループ\n",
    "    for filename in combined_list:\n",
    "        loaded_data = np.load(filename, allow_pickle=True)\n",
    "        ghost_results, ghost_results_shifted = loaded_data\n",
    "        data = [shifted - original for original, shifted in zip(ghost_results, ghost_results_shifted)]\n",
    "        data_tensor = torch.tensor(data)\n",
    "\n",
    "        final_QP = extract_finalQP(filename)\n",
    "\n",
    "        is_double_score = is_double_compressed(data_tensor, final_QP, threshold)\n",
    "        results.append((filename, is_double_score))\n",
    "\n",
    "        # ファイル名に基づいて実際のクラスを設定\n",
    "        if \"2ndQP\" in filename:\n",
    "            ground_truth_labels.append(1)\n",
    "        else:\n",
    "            ground_truth_labels.append(0)\n",
    "\n",
    "    # Classification report\n",
    "    predicted_scores = [int(is_double_score) for _, is_double_score in results]\n",
    "\n",
    "    # ROC 曲線の計算\n",
    "    fpr, tpr, _ = roc_curve(ground_truth_labels, predicted_scores)\n",
    "\n",
    "    # FPRとTPRをリストに追加\n",
    "    fpr_values.append(fpr)\n",
    "    tpr_values.append(tpr)\n",
    "    \n",
    "\n",
    "fprs = [arr[1] for arr in fpr_values]\n",
    "tprs = [arr[1] for arr in tpr_values]\n",
    "last_fprs = fprs.pop()\n",
    "last_tprs = tprs.pop()\n",
    "fprs.insert(0, last_fprs)\n",
    "tprs.insert(0, last_tprs)\n",
    "fprs.append(0)\n",
    "tprs.append(0)\n",
    "roc_auc = auc(fprs, tprs)\n",
    "\n",
    "    \n",
    "# ROC曲線のプロット\n",
    "    \n",
    "plt.figure\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fprs, tprs, color='darkorange', marker='.',markersize=20, label='AUC = %0.2f' % roc_auc, markerfacecolor='navy')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "# plt.savefig('roc_curve.png', bbox_inches='tight', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87faad4e-038c-4c3b-a9ea-fe9806b24534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            ax.text(j, i, f'{data[i, j]:.0f}', ha='center', va='center', color='w')\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.0f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max()) / 2.\n",
    "\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587037f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp_labels = [10, 15, 20, 25, 30, 32, 35, 40, 45, 50]\n",
    "none = 0\n",
    "\n",
    "heatmap_data = np.zeros((len(qp_labels), len(qp_labels)), dtype=int)\n",
    "\n",
    "for filename in files_double:\n",
    "    loaded_data = np.load(filename, allow_pickle=True)\n",
    "    ghost_results, ghost_results_shifted = loaded_data\n",
    "    data = [shifted - original for original, shifted in zip(ghost_results, ghost_results_shifted)]    \n",
    "    data_tensor = torch.tensor(data)\n",
    "\n",
    "    final_QP = extract_finalQP(filename)\n",
    "    true_QP = extract_1stQP(filename)\n",
    "    possible_QP, _, _ = get_possible_1stQP(data_tensor, final_QP)\n",
    "    \n",
    "    \n",
    "    if possible_QP is not None:\n",
    "        if possible_QP == true_QP:\n",
    "            heatmap_data[qp_labels.index(true_QP), qp_labels.index(possible_QP)] += 1\n",
    "\n",
    "        elif (possible_QP != true_QP) & (possible_QP in qp_labels):\n",
    "            heatmap_data[qp_labels.index(true_QP), qp_labels.index(possible_QP)] += 1\n",
    "    else:\n",
    "        none+=1\n",
    "print('None: ', none)\n",
    "        \n",
    "        \n",
    "# Create and display the heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "im, cbar = heatmap(heatmap_data, qp_labels, qp_labels, ax=ax, cmap=plt.cm.Blues)\n",
    "annotate_heatmap(im, valfmt=\"{x:.0f}\")\n",
    "\n",
    "plt.title('Heatmap of True vs Predicted 1stQP')\n",
    "plt.xlabel('Predicted 1stQP')\n",
    "plt.ylabel('True 1stQP')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce39320-2795-4459-a339-6ce0f16f95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 10 # 全体のフォントサイズが変更されます。\n",
    "plt.rcParams['figure.figsize'] = (3.5, 3.5) \n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "qp_labels = [10, 15, 20, 25, 30, 32, 35, 40, 45, 50]\n",
    "total_counts = [150, 300, 450, 750, 900, 900, 1050, 1200, 1350, 1500]\n",
    "none = 0\n",
    "\n",
    "heatmap_data = np.zeros((len(qp_labels), len(qp_labels)), dtype=int)\n",
    "\n",
    "for filename in files_double:\n",
    "    loaded_data = np.load(filename, allow_pickle=True)\n",
    "    ghost_results, ghost_results_shifted = loaded_data\n",
    "    data = [shifted - original for original, shifted in zip(ghost_results, ghost_results_shifted)]    \n",
    "    data_tensor = torch.tensor(data)\n",
    "\n",
    "    final_QP = extract_finalQP(filename)\n",
    "    true_QP = extract_1stQP(filename)\n",
    "    possible_QP, _, _ = get_possible_1stQP(data_tensor, final_QP)\n",
    "    \n",
    "    \n",
    "    if possible_QP is not None:\n",
    "        if possible_QP == true_QP:\n",
    "            heatmap_data[qp_labels.index(true_QP), qp_labels.index(possible_QP)] += 1\n",
    "\n",
    "        elif (possible_QP != true_QP) & (possible_QP in qp_labels):\n",
    "            heatmap_data[qp_labels.index(true_QP), qp_labels.index(possible_QP)] += 1\n",
    "    else:\n",
    "        none+=1\n",
    "print('None: ', none)\n",
    "\n",
    "for i in range(len(qp_labels)):\n",
    "    for j in range(len(qp_labels)):\n",
    "        heatmap_data[i,j] = (heatmap_data[i,j]/total_counts[i])*100\n",
    "        \n",
    "# Create and display the heatmap\n",
    "fig, ax = plt.subplots()\n",
    "im, cbar = heatmap(heatmap_data, qp_labels, qp_labels, ax=ax, cmap=plt.cm.Blues)\n",
    "cbar.remove()\n",
    "annotate_heatmap(im, valfmt=\"{x:.0f}\")\n",
    "\n",
    "# plt.title('Heatmap of True vs Predicted 1stQP (%)')\n",
    "plt.xlabel('Predicted 1stQP')\n",
    "plt.ylabel('True 1stQP')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('heatmap_percentage.png', bbox_inches='tight', dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('heatmap_medium0.pdf', bbox_inches=\"tight\", pad_inches=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
